<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>后门 on k1te's blog</title><link>https://k1te.cn/tags/%E5%90%8E%E9%97%A8/</link><description>Recent content in 后门 on k1te's blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 11 Oct 2024 17:28:36 +0800</lastBuildDate><atom:link href="https://k1te.cn/tags/%E5%90%8E%E9%97%A8/index.xml" rel="self" type="application/rss+xml"/><item><title>论文阅读：Progressive Backdoor Erasing via connecting Backdoor and Adversarial Attacks</title><link>https://k1te.cn/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBprogressive-backdoor-erasing-via-connecting-backdoor-and-adversarial-attacks/</link><pubDate>Fri, 11 Oct 2024 17:28:36 +0800</pubDate><guid>https://k1te.cn/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBprogressive-backdoor-erasing-via-connecting-backdoor-and-adversarial-attacks/</guid><description>&lt;p>CVPR 2023, Xi’an Jiaotong University、Xidian University
代码地址：https://github.com/John-niu-07/BPE&lt;/p>
&lt;h3 id="摘要">摘要
&lt;/h3>&lt;p>众所周知，深度神经网络(DNN)既容易受到后门攻击，也容易受到对手攻击。在文献中，这两类攻击通常被视为不同的问题，分别属于训练时间攻击和推理时间攻击。然而，在本文中，我们发现了它们之间一个有趣的联系：对于一个植入后门的模型，我们观察到其敌对示例与其触发图像具有相似的行为，即两者都激活了相同的DNN神经元子集。它表明，在模型中植入后门将显著影响模型的对抗性示例。基于这些观察结果，提出了一种新的渐进式后门擦除(PBE)算法，通过利用非目标对抗性攻击来逐步净化受感染的模型。与以前的后门防御方法不同，我们方法的一个显著优势是，即使在干净的额外数据集不可用的情况下，它也可以擦除后门。我们的实验表明，对于5种最先进的后门攻击，我们的PBE可以有效地擦除后门，而对干净的样本没有明显的性能下降，并且性能优于现有的防御方法。&lt;/p></description></item></channel></rss>